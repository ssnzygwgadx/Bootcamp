{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data': array([[ 0.04,  0.05,  0.06, ..., -0.  ,  0.02, -0.02],\n",
       "        [-0.  , -0.04, -0.05, ..., -0.04, -0.07, -0.09],\n",
       "        [ 0.09,  0.05,  0.04, ..., -0.  ,  0.  , -0.03],\n",
       "        ...,\n",
       "        [ 0.04,  0.05, -0.02, ..., -0.01, -0.05,  0.02],\n",
       "        [-0.05, -0.04,  0.04, ...,  0.03,  0.04, -0.03],\n",
       "        [-0.05, -0.04, -0.07, ..., -0.04, -0.  ,  0.  ]]),\n",
       " 'target': array([151.,  75., 141., 206., 135.,  97., 138.,  63., 110., 310., 101.,\n",
       "         69., 179., 185., 118., 171., 166., 144.,  97., 168.,  68.,  49.,\n",
       "         68., 245., 184., 202., 137.,  85., 131., 283., 129.,  59., 341.,\n",
       "         87.,  65., 102., 265., 276., 252.,  90., 100.,  55.,  61.,  92.,\n",
       "        259.,  53., 190., 142.,  75., 142., 155., 225.,  59., 104., 182.,\n",
       "        128.,  52.,  37., 170., 170.,  61., 144.,  52., 128.,  71., 163.,\n",
       "        150.,  97., 160., 178.,  48., 270., 202., 111.,  85.,  42., 170.,\n",
       "        200., 252., 113., 143.,  51.,  52., 210.,  65., 141.,  55., 134.,\n",
       "         42., 111.,  98., 164.,  48.,  96.,  90., 162., 150., 279.,  92.,\n",
       "         83., 128., 102., 302., 198.,  95.,  53., 134., 144., 232.,  81.,\n",
       "        104.,  59., 246., 297., 258., 229., 275., 281., 179., 200., 200.,\n",
       "        173., 180.,  84., 121., 161.,  99., 109., 115., 268., 274., 158.,\n",
       "        107.,  83., 103., 272.,  85., 280., 336., 281., 118., 317., 235.,\n",
       "         60., 174., 259., 178., 128.,  96., 126., 288.,  88., 292.,  71.,\n",
       "        197., 186.,  25.,  84.,  96., 195.,  53., 217., 172., 131., 214.,\n",
       "         59.,  70., 220., 268., 152.,  47.,  74., 295., 101., 151., 127.,\n",
       "        237., 225.,  81., 151., 107.,  64., 138., 185., 265., 101., 137.,\n",
       "        143., 141.,  79., 292., 178.,  91., 116.,  86., 122.,  72., 129.,\n",
       "        142.,  90., 158.,  39., 196., 222., 277.,  99., 196., 202., 155.,\n",
       "         77., 191.,  70.,  73.,  49.,  65., 263., 248., 296., 214., 185.,\n",
       "         78.,  93., 252., 150.,  77., 208.,  77., 108., 160.,  53., 220.,\n",
       "        154., 259.,  90., 246., 124.,  67.,  72., 257., 262., 275., 177.,\n",
       "         71.,  47., 187., 125.,  78.,  51., 258., 215., 303., 243.,  91.,\n",
       "        150., 310., 153., 346.,  63.,  89.,  50.,  39., 103., 308., 116.,\n",
       "        145.,  74.,  45., 115., 264.,  87., 202., 127., 182., 241.,  66.,\n",
       "         94., 283.,  64., 102., 200., 265.,  94., 230., 181., 156., 233.,\n",
       "         60., 219.,  80.,  68., 332., 248.,  84., 200.,  55.,  85.,  89.,\n",
       "         31., 129.,  83., 275.,  65., 198., 236., 253., 124.,  44., 172.,\n",
       "        114., 142., 109., 180., 144., 163., 147.,  97., 220., 190., 109.,\n",
       "        191., 122., 230., 242., 248., 249., 192., 131., 237.,  78., 135.,\n",
       "        244., 199., 270., 164.,  72.,  96., 306.,  91., 214.,  95., 216.,\n",
       "        263., 178., 113., 200., 139., 139.,  88., 148.,  88., 243.,  71.,\n",
       "         77., 109., 272.,  60.,  54., 221.,  90., 311., 281., 182., 321.,\n",
       "         58., 262., 206., 233., 242., 123., 167.,  63., 197.,  71., 168.,\n",
       "        140., 217., 121., 235., 245.,  40.,  52., 104., 132.,  88.,  69.,\n",
       "        219.,  72., 201., 110.,  51., 277.,  63., 118.,  69., 273., 258.,\n",
       "         43., 198., 242., 232., 175.,  93., 168., 275., 293., 281.,  72.,\n",
       "        140., 189., 181., 209., 136., 261., 113., 131., 174., 257.,  55.,\n",
       "         84.,  42., 146., 212., 233.,  91., 111., 152., 120.,  67., 310.,\n",
       "         94., 183.,  66., 173.,  72.,  49.,  64.,  48., 178., 104., 132.,\n",
       "        220.,  57.]),\n",
       " 'frame': None,\n",
       " 'DESCR': '.. _diabetes_dataset:\\n\\nDiabetes dataset\\n----------------\\n\\nTen baseline variables, age, sex, body mass index, average blood\\npressure, and six blood serum measurements were obtained for each of n =\\n442 diabetes patients, as well as the response of interest, a\\nquantitative measure of disease progression one year after baseline.\\n\\n**Data Set Characteristics:**\\n\\n  :Number of Instances: 442\\n\\n  :Number of Attributes: First 10 columns are numeric predictive values\\n\\n  :Target: Column 11 is a quantitative measure of disease progression one year after baseline\\n\\n  :Attribute Information:\\n      - age     age in years\\n      - sex\\n      - bmi     body mass index\\n      - bp      average blood pressure\\n      - s1      tc, T-Cells (a type of white blood cells)\\n      - s2      ldl, low-density lipoproteins\\n      - s3      hdl, high-density lipoproteins\\n      - s4      tch, thyroid stimulating hormone\\n      - s5      ltg, lamotrigine\\n      - s6      glu, blood sugar level\\n\\nNote: Each of these 10 feature variables have been mean centered and scaled by the standard deviation times `n_samples` (i.e. the sum of squares of each column totals 1).\\n\\nSource URL:\\nhttps://www4.stat.ncsu.edu/~boos/var.select/diabetes.html\\n\\nFor more information see:\\nBradley Efron, Trevor Hastie, Iain Johnstone and Robert Tibshirani (2004) \"Least Angle Regression,\" Annals of Statistics (with discussion), 407-499.\\n(https://web.stanford.edu/~hastie/Papers/LARS/LeastAngle_2002.pdf)',\n",
       " 'feature_names': ['age',\n",
       "  'sex',\n",
       "  'bmi',\n",
       "  'bp',\n",
       "  's1',\n",
       "  's2',\n",
       "  's3',\n",
       "  's4',\n",
       "  's5',\n",
       "  's6'],\n",
       " 'data_filename': '/Users/huruixin/opt/anaconda3/lib/python3.8/site-packages/sklearn/datasets/data/diabetes_data.csv.gz',\n",
       " 'target_filename': '/Users/huruixin/opt/anaconda3/lib/python3.8/site-packages/sklearn/datasets/data/diabetes_target.csv.gz'}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the code from the last work book\n",
    "from sklearn.datasets import load_diabetes\n",
    "from sklearn.tree import DecisionTreeRegressor as DTR\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# import the data\n",
    "data = load_diabetes()\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'criterion': ['squared_error', 'absolute_error']}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# You'll need these for hyperparameter optimisation\n",
    "\n",
    "scores = ['neg_mean_squared_error', 'r2']\n",
    "{'criterion': ['squared_error', 'absolute_error']}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "neg_mean_squared_error:\n",
    "åœ¨sklearnå½“ä¸­ï¼Œæˆ‘ä»¬æœ‰ä¸¤ç§æ–¹å¼è°ƒç”¨è¿™ä¸ªè¯„ä¼°æŒ‡æ ‡ï¼Œä¸€ç§æ˜¯ä½¿ç”¨sklearnä¸“ç”¨çš„æ¨¡å‹è¯„ä¼°æ¨¡å—metricsé‡Œçš„ç±»mean_squared_errorï¼Œå¦ä¸€ç§æ˜¯è°ƒç”¨äº¤å‰éªŒè¯çš„ç±»cross_val_scoreå¹¶ä½¿ç”¨é‡Œé¢çš„scoringå‚æ•°æ¥è®¾ç½®ä½¿ç”¨å‡æ–¹è¯¯å·®ã€‚cross_val_scoreçš„å‡æ–¹è¯¯å·®ä¸ºè´Ÿã€‚æˆ‘ä»¬åœ¨å†³ç­–æ ‘å’Œéšæœºæ£®æ—ä¸­éƒ½æåˆ°è¿‡ï¼Œè™½ç„¶å‡æ–¹è¯¯å·®æ°¸è¿œä¸ºæ­£ï¼Œä½†æ˜¯sklearnä¸­çš„å‚æ•°scoringä¸‹ï¼Œå‡æ–¹è¯¯å·®ä½œä¸ºè¯„åˆ¤æ ‡å‡†æ—¶ï¼Œå´æ˜¯è®¡ç®—â€è´Ÿå‡æ–¹è¯¯å·®â€œï¼ˆneg_mean_squared_errorï¼‰ã€‚è¿™æ˜¯å› ä¸ºsklearnåœ¨è®¡ç®—æ¨¡å‹è¯„ä¼°æŒ‡æ ‡çš„æ—¶å€™ï¼Œä¼šè€ƒè™‘æŒ‡æ ‡æœ¬èº«çš„æ€§è´¨ï¼Œå‡æ–¹è¯¯å·®æœ¬èº«æ˜¯ä¸€ç§è¯¯å·®ï¼Œæ‰€ä»¥è¢«sklearnåˆ’åˆ†ä¸ºæ¨¡å‹çš„ä¸€ç§æŸå¤±(loss)ã€‚åœ¨sklearnå½“ä¸­ï¼Œæ‰€æœ‰çš„æŸå¤±éƒ½ä½¿ç”¨è´Ÿæ•°è¡¨ç¤ºï¼Œå› æ­¤å‡æ–¹è¯¯å·®ä¹Ÿè¢«æ˜¾ç¤ºä¸ºè´Ÿæ•°äº†ã€‚çœŸæ­£çš„å‡æ–¹è¯¯å·®MSEçš„æ•°å€¼ï¼Œå…¶å®å°±æ˜¯neg_mean_squared_errorå»æ‰è´Ÿå·çš„æ•°å­—ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn import tree\n",
    "from sklearn.tree import DecisionTreeClassifier as DTC\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#4. Separate the target (ğ’€) from the features (ğ‘¿s)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a DataFrame of features \n",
    "diabetes_df = pd.DataFrame(data.data, columns=data.feature_names)\n",
    "\n",
    "# normalise the data\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "\n",
    "scaler = RobustScaler()\n",
    "df = scaler.fit_transform(diabetes_df)\n",
    "diabetes_df = pd.DataFrame(df, columns=data.feature_names)\n",
    "\n",
    "# create a target variable\n",
    "diabetes_target = data.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#5. Split the data into training and test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection  import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(diabetes_df, diabetes_target, test_size = 0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "#6. Run the model on the training data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit a decision tree to the training data\n",
    "tree_model = DTC()\n",
    "tree_model_fit = tree_model.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "#7. Check the performance metrics / score\n",
    "# scores = ['neg_mean_squared_error', 'r2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model performance\n",
      "--------------------------------------\n",
      "rmse is 83.43126081331191\n",
      "r2 score is -0.18877815161185318\n"
     ]
    }
   ],
   "source": [
    "# predict every Y value in the test data\n",
    "predicted = tree_model_fit.predict(X_test)\n",
    "\n",
    "# calculate RMSE (root mean square error) and R^2 (predictive power)\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "rmse = (np.sqrt(mean_squared_error(Y_test, predicted)))\n",
    "r2 = r2_score(Y_test, predicted)\n",
    "\n",
    "# print the performance metrics\n",
    "print(\"Model performance\")\n",
    "print(\"--------------------------------------\")\n",
    "print(f'rmse is {rmse}')\n",
    "print(f'r2 score is {r2}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "#8. Optimise hyperparameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['rmse', 'r2']"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "tuned_parameters = [{'criterion': ['squared_error', 'absolute_error'],\n",
    "                     'max_depth': [3, 5, 7],\n",
    "                     'min_samples_split': [3, 5, 7],\n",
    "                     'max_features': [\"sqrt\", \"log2\", None]}]\n",
    "\n",
    "scores = ['rmse', 'r2']\n",
    "\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for score in scores:\n",
    "    print(\"# Tuning hyperparameters for %s\" % score)\n",
    "    print(\"\\n\")\n",
    "    clf = GridSearchCV(DTC(), tuned_parameters, cv=5,\n",
    "                       scoring= score)\n",
    "    clf.fit(X_train, Y_train)\n",
    "    print(\"Best parameters set found on the training set:\")\n",
    "    print(clf.best_params_)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "#9. Check the performance metrics / score again\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
